{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset import COCO2CLIPDataset, PACCO2CLIPDataset\n",
    "from src.metrics import get_image_and_text_tensor\n",
    "from src.train_util import get_name, do_train\n",
    "from src.model import CrossAttentionModule, MLPs\n",
    "from src.eval_util import do_eval\n",
    "from src.plots_util import plot_losses, plot_values, bcolors\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import yaml \n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = 'cuda:7'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results, warmup=True, limit=None):\n",
    "    if limit is not None:\n",
    "        for field, results_type in results.items():\n",
    "            for type, to_cut in results_type.items():\n",
    "                results[field][type] = to_cut[:limit] if to_cut is not None else None\n",
    "    losses = results['losses']\n",
    "    labels = [\"Training Loss PACCO\", \"Validation Loss PACCO\", 'Validation Loss COCO'] if losses['additional_val_loss'] is not None else [\"Training Loss COCO\", \"Validation Loss COCO\", 'Validation Loss COCO']\n",
    "    plot_losses(losses['train_loss'], losses['val_loss'], additional_val_losses=losses['additional_val_loss'], labels=labels, plot=True, warmup=warmup)   \n",
    "    if results['mean_rank_sums'] is not None:\n",
    "        pacco_results, clip_pacco_results = results['mean_rank_sums']['mean_rank_sums'], results['mean_rank_sums']['clip_mean_rank_sums']\n",
    "        plot_values([pacco_results, clip_pacco_results], ['Current Model', 'CLIP B/16'], 'Mean Rank Sum', 'Mean Rank sum on PACCO Validation set', warmup=warmup)\n",
    "    if results['rsums']is not None:\n",
    "        rsums, clip_rsums = results['rsums']['rsums'], results['rsums']['clip_rsums'] \n",
    "        plot_values([rsums, clip_rsums], ['Current Model', 'CLIP B/16'], 'rsum', 'rsum on COCO', warmup=warmup)\n",
    "        \n",
    "def train_test_save(model_name, train_dataset, val_dataset, test1k_imm=None, test1k_txt=None, model=None, additional_val_dataset=None, warmup=True):\n",
    "    out_path = os.path.join('checkpoints', f'{model_name}.pth')\n",
    "    # loss_path = os.path.join('checkpoints', 'loss', f'{model_name}.jpg')\n",
    "\n",
    "    train_config = model_name.split('_')[0]\n",
    "    model_config = model_name[model_name.find('_') + 1:]\n",
    "    train_config_path = f\"configs/train/{train_config}.yaml\"\n",
    "    model_config_path = f\"configs/model/{model_config}.yaml\"\n",
    "    config = {}\n",
    "    with open(train_config_path, 'r') as config_file:\n",
    "        config['train'] = yaml.safe_load(config_file)\n",
    "    with open(model_config_path, 'r') as config_file:\n",
    "        config['model'] = yaml.safe_load(config_file)\n",
    "    print(f\"Configuration loaded!\\n{json.dumps(config, indent=2)}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{bcolors.BOLD}{bcolors.UNDERLINE}{model_name}{bcolors.ENDC}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    if model is None:\n",
    "        # model loading\n",
    "        if 'num_attention_layers' in config['model']:\n",
    "            model = CrossAttentionModule.from_config(config['model'])\n",
    "        else:\n",
    "            model = MLPs.from_config(config['model'])\n",
    "        model.to(device)\n",
    "\n",
    "    model = do_train(model, train_dataset, val_dataset, config['train'], plot=True, loss_path=None, additional_val_dataset=additional_val_dataset, warmup=warmup)\n",
    "    do_eval(model, model_name, test1k_imm, test1k_txt)\n",
    "    torch.save(model.state_dict(), out_path)\n",
    "    return model\n",
    "\n",
    "def show_results(model_name=None, test1k_imm=None, test1k_txt=None, show_loss=True, plotting_results=False, evaluate=True, limit=None, warmup=True):\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"{bcolors.BOLD}{bcolors.UNDERLINE}{model_name}{bcolors.ENDC}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    # config_path = f'configs/{model_name}.yaml'\n",
    "    # with open(config_path, 'r') as config_file:\n",
    "    #     config = yaml.safe_load(config_file)\n",
    "    train_config = model_name.split('_')[0]\n",
    "    model_config = model_name[model_name.find('_') + 1:]\n",
    "    train_config_path = f\"configs/train/{train_config}.yaml\"\n",
    "    model_config_path = f\"configs/model/{model_config}.yaml\"\n",
    "    config = {}\n",
    "    with open(train_config_path, 'r') as config_file:\n",
    "        config['train'] = yaml.safe_load(config_file)\n",
    "    with open(model_config_path, 'r') as config_file:\n",
    "        config['model'] = yaml.safe_load(config_file)\n",
    "    print(f\"Configuration loaded!\\n{json.dumps(config, indent=2)}\")\n",
    "\n",
    "    if plotting_results:\n",
    "        results = torch.load(f'checkpoints/results/{model_name}.pt')\n",
    "        plot_results(results, warmup, limit)\n",
    "    if show_loss:\n",
    "        print(\"Training losses:\")\n",
    "        loss = cv2.imread(f'checkpoints/loss/{model_name}.jpg')\n",
    "        loss = cv2.cvtColor(loss, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Display the image using Matplotlib\n",
    "        plt.imshow(loss)\n",
    "        plt.axis('off')  # Optional: Turn off axis labels\n",
    "        plt.show()\n",
    "    if evaluate:\n",
    "        # model loading\n",
    "        if 'num_attention_layers' in config['model']:\n",
    "            model = CrossAttentionModule.from_config(config['model'])\n",
    "        else:\n",
    "            model = MLPs.from_config(config['model'])\n",
    "        model.load_state_dict(torch.load(f\"checkpoints/{model_name}.pth\", device))\n",
    "        model.to(device)\n",
    "\n",
    "        do_eval(model, model_name, test1k_imm, test1k_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded!\n",
      "Loading dataset...\n",
      "Dataset loaded!\n"
     ]
    }
   ],
   "source": [
    "train_dataset = COCO2CLIPDataset('./features/ViT-B-16/train.json')\n",
    "val_dataset = COCO2CLIPDataset('./features/ViT-B-16/val.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset loaded!\n",
      "Loading dataset...\n",
      "Dataset loaded!\n"
     ]
    }
   ],
   "source": [
    "hard_train_dataset = PACCO2CLIPDataset('./fg-ovd_feature_extraction/training_sets/1_attributes.pt')\n",
    "medium_train_dataset = PACCO2CLIPDataset('./fg-ovd_feature_extraction/training_sets/2_attributes.pt')\n",
    "easy_train_dataset = PACCO2CLIPDataset('./fg-ovd_feature_extraction/training_sets/3_attributes.pt')\n",
    "trivial_train_dataset = PACCO2CLIPDataset('./fg-ovd_feature_extraction/training_sets/shuffle_negatives.pt')\n",
    "hard_val_dataset = PACCO2CLIPDataset('./fg-ovd_feature_extraction/val_sets/1_attributes.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 4198.44it/s]\n"
     ]
    }
   ],
   "source": [
    "test1k_imm, test1k_txt = get_image_and_text_tensor('features/ViT-B-16/test1k.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
